joints_renderer:
  _target_: src.renderer.matplotlib.MatplotlibRender
  jointstype: "guoh3djoints"
  fps: 20.0
  colors: ['black', 'magenta', 'red', 'green', 'blue']
  figsize: 4
  canonicalize: true

smpl_renderer:
  _target_: src.renderer.humor.HumorRenderer
  fps: 20.0
  imw: 720
  imh: 720

diffusion:
  weight: 1.0
  mcd: True

  denoiser:
    dropout: 0.0

dataloader:
  _target_: torch.utils.data.DataLoader
  batch_size: 16 # 128
  num_workers: 12

# Pretrained model parameters
ckpt_name: 'logs/checkpoints/last.ckpt'
dataset: humanml3d # kitml
run_dir: pretrained_models/mdm-smpl_clip_smplrifke_humanml3d
input_type: auto # timeline / text
single_frame: false # render or not summary frame with smpl
gender: male

guidance_weight: 1.0
baseline: none

overlap_s: 0.5
ckpt: last
device: cuda
value_from: smpl


# General parameters
num_gen_per_prompt: 4
num_prompts_dataset: 32
num_workers: 6

# Training parameters
iterations: 1000
train_epochs: 4
train_batch_size: 48
grad_clip: 1.0
advantage_clip_epsilon: 1e-4

# Reward Model
tmr_reward: true
masking_ratio: 0.75
reward_scale: 10

# Sequence parameters
fps: 20
time: 2.5
joint_stype: "both"  # Can be either "both" or "smpljoints"

# Optimizer parameters
lr: 1e-5
beta1: 0.9
beta2: 0.999
eps: 1e-8
weight_decay: 1e-4

# Loss parameters
betaL: 0
alphaL: 1

# Validation/Test parameters
val_iter: 25
val_batch_size: 16
val_num_batch: 4

dataset_name: ''

#Layer freeze
freeze_normalization_layers: true

#LorA
lora: false
lora_rank: 4
lora_alpha: 16
lora_dropout: 0.1

# WanDB parameters
experiment_name: 'New_'
group_name: ''
